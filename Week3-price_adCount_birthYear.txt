Welcome to Week 3



This document provides a running example of completing the Week 3 assignment :

    A shorter version with fewer comments is available as script: sparkMLlibClustering.py
    To run these commands in Cloudera VM: first run the setup script: setupWeek3.sh
    You can then copy paste these commands in pySpark.
    To open pySpark, refer to : Week 2 and Week 4 of the Machine Learning course

PYSPARK_DRIVER_PYTHON=ipython pyspark

    Note that your dataset may be different from what is used here, so your results may not match with those shown here


Finally, make sure that your working directory contains the data files (.csv) for the fastest support.
We recommend workng in your home directory (type cd ~ in your terminal). Please run any scripts using your terminal for 
proper settings.
In [1]:

import pandas as pd
from pyspark.mllib.clustering import KMeans, KMeansModel
from numpy import array

Step 1: Attribute Selection

Import Data

First let us read the contents of the file ad-clicks.csv. The following commands read in the CSV file in a table format and 
removes any extra whitespaces. So, if the CSV contained ' userid ' it becomes 'userid'.

Note that you must change the path to ad-clicks.csv to the location on your machine, if you want to run this command on 
your machine.

### users.csv has a dob column, if we want to get the birthYear as an attribute ###

In [2]:

adclicksDF = pd.read_csv('./ad-clicks.csv')
adclicksDF = adclicksDF.rename(columns=lambda x: x.strip()) #remove whitespaces from headers

Let us display the first 5 lines of adclicksDF:

In [3]:

adclicksDF.head(n=5)

Out[3]:
#	timestamp 	txId 	userSessionId 	teamId 	userId 	adId 	adCategory
#0 	2016-05-30 14:24:03 	6616 	6289 	24 	876 	29 	movies
#1 	2016-05-30 14:24:47 	6624 	6144 	29 	1935 	8 	games
#2 	2016-05-30 14:26:34 	6628 	6536 	20 	1588 	25 	movies
#3 	2016-05-30 14:26:50 	6618 	6518 	21 	1195 	19 	fashion
#4 	2016-05-30 14:27:06 	6629 	6072 	146 	1685 	20 	games

             timestamp  txId  userSessionId  teamId  userId  adId   adCategory
0  2016-05-26 15:13:22  5974           5809      27     611     2  electronics
1  2016-05-26 15:17:24  5976           5705      18    1874    21       movies
2  2016-05-26 15:22:52  5978           5791      53    2139    25    computers
3  2016-05-26 15:22:57  5973           5756      63     212    10      fashion
4  2016-05-26 15:22:58  5980           5920       9    1027    20     clothing


Next, We are going to add an extra column to the ad-clicks table and make it equal to 1. We do so to record the fact that 
each ROW is 1 ad-click. You will see how this will become useful when we sum up this column to find how many ads did a user 
click.

In [4]:

adclicksDF['adCount'] = 1

Let us display the first 5 lines of adclicksDF and see if a new column has been added:

In [5]:

adclicksDF.head(n=5)

Out[5]:
#	timestamp 	txId 	userSessionId 	teamId 	userId 	adId 	adCategory 	adCount
#0 	2016-05-30 14:24:03 	6616 	6289 	24 	876 	29 	movies 	1
#1 	2016-05-30 14:24:47 	6624 	6144 	29 	1935 	8 	games 	1
#2 	2016-05-30 14:26:34 	6628 	6536 	20 	1588 	25 	movies 	1
#3 	2016-05-30 14:26:50 	6618 	6518 	21 	1195 	19 	fashion 	1
#4 	2016-05-30 14:27:06 	6629 	6072 	146 	1685 	20 	games 	1

             timestamp  txId  userSessionId  teamId  userId  adId  adCategory  adCount
0  2016-05-26 15:13:22  5974           5809      27     611     2  electronics        1
1  2016-05-26 15:17:24  5976           5705      18    1874    21  movies        1
2  2016-05-26 15:22:52  5978           5791      53    2139    25  computers        1
3  2016-05-26 15:22:57  5973           5756      63     212    10  fashion        1
4  2016-05-26 15:22:58  5980           5920       9    1027    20  clothing        1

Next, let us read the contents of the file buy-clicks.csv. As before, the following commands read in the CSV file in a 
table format and removes any extra whitespaces. So, if the CSV contained ' userid ' it becomes 'userid'.

Note that you must change the path to buy-clicks.csv to the location on your machine, if you want to run this command on 
your machine.

In [6]:

buyclicksDF = pd.read_csv('./buy-clicks.csv')
buyclicksDF = buyclicksDF.rename(columns=lambda x: x.strip()) #removes whitespaces from headers

Let us display the first 5 lines of buyclicksDF:

In [7]:

buyclicksDF.head(n=5)

Out[7]:
#	timestamp 	txId 	userSessionId 	team 	userId 	buyId 	price
#0 	2016-05-30 13:51:50 	6587 	6368 	29 	1422 	2 	3
#1 	2016-05-30 13:51:50 	6588 	6440 	112 	2253 	0 	1
#2 	2016-05-30 13:51:50 	6589 	6420 	48 	1393 	2 	3
#3 	2016-05-30 14:21:50 	6631 	6495 	141 	2295 	2 	3
#4 	2016-05-30 14:21:50 	6632 	6111 	119 	1560 	0 	1

             timestamp  txId  userSessionId  team  userId  buyId  price
0  2016-05-26 15:36:54  6004           5820     9    1300      2    3.0
1  2016-05-26 15:36:54  6005           5775    35     868      4   10.0
2  2016-05-26 15:36:54  6006           5679    97     819      5   20.0
3  2016-05-26 16:36:54  6067           5665    18     121      2    3.0
4  2016-05-26 17:06:54  6093           5709    11    2222      5   20.0

Then we read the contents of users.csv.

#usersDF = pd.read_csv('./users.csv')
# probably better to get the dob column values cast to datetime at this stage, so we can extract the year later

usersDF = pd.read_csv('./users.csv', sep=",", parse_dates=["dob"]) # OK, but we just want the year
 ... need the datetime cast, though, so I guees this is good enough
usersDF.dtypes # verfiies dob column values are datetime64[ns] ... works!

usersDF = usersDF.rename(columns=lambda x: x.strip()) #removes whitespaces from headers

Let us display the first 5 lines of usersDF:

usersDF.head(n=5)

Out:
             timestamp  userId         nick   twitter         dob country
0  2012-06-19 14:53:41     442     pcjIOBKW  @SZhyOHv  1994-07-20      BA
1  2012-06-19 19:29:01     949      vAOfUkf    @nkkNo  1971-04-22      HU
2  2012-06-20 19:34:59    1654       qOOXSQ    @SwOlw  1970-04-19      IS
3  2012-06-21 01:18:29    1586      px4gW51  @IrCHTnE  1965-11-23      AM
4  2012-06-21 15:35:00     599  9gkfwRC73Uc   @VJj0Az  1994-08-23      CC

Feature Selection

For this exercise, we can choose from buyclicksDF, the 'price' of each app that a user purchases as an attribute that 
captures user's purchasing behavior. The following command selects 'userid' and 'price' and drops all other columns that 
we do not want to use at this stage.

In [8]:

userPurchases = buyclicksDF[['userId','price']] #select only userid and price
userPurchases.head(n=5)

Out[8]:
#	userId 	price
#0 	1422 	3
#1 	2253 	1
#2 	1393 	3
#3 	2295 	3
#4 	1560 	1

   userId  price
0    1300    3.0
1     868   10.0
2     819   20.0
3     121    3.0
4    2222   20.0

Similarly, from the adclicksDF, we will use the 'adCount' as an attribute that captures user's inclination to click on ads. 
The following command selects 'userid' and 'adCount' and drops all other columns that we do not want to use at this stage.

In [9]:

useradClicks = adclicksDF[['userId','adCount']]

In [10]:

useradClicks.head(n=5) #as we saw before, this line displays first five lines

Out[10]:
#	userId 	adCount
#0 	876 	1
#1 	1935 	1
#2 	1588 	1
#3 	1195 	1
#4 	1685 	1

   userId  adCount
0     611        1
1    1874        1
2    2139        1
3     212        1
4    1027        1

Then we do the same with usersDF. Also getting the birthYear from dob values.

#usersDOB['birthYear'] = pd.to_datetime(usersDOB['dob'].dt.year # not working

#usersDOB['birthYear'] = pd.to_datetime(usersDOB['dob'].dt.year) #error: name 'usersDOB' is not defined

#usersDF['birthYear'] = pd.to_datetime(usersDF['dob'].dt.year) # error: Can only use .dt accessor with datetimelike values

#usersDF['birthYear'] = pd.to_datetime(usersDF['dob'], format='%Y') # appears to_datetime is silently failing
# ... mabe wome rows are not in correct format?

#usersDF['birthYear'] = pd.to_datetime(usersDF['dob'], format='%Y', coerce=True) # FutureWarning: the coerce=True keyword is deprecated, use errors='coerce' instead

#usersDF['birthYear'] = pd.to_datetime(usersDF['dob'], format='%Y', errors='coerce')

usersDF['birthYear'] = pd.to_datetime(usersDF['dob'].dt.year)

#usersDF['birthYear'] = pd.to_datetime.map(lambda x: x.strftime('%y))

usersDOB = usersDF[['userId','birthYear']]

usersDOB.head(n=5)

Out[24]: 
   userId                     birthYear
0     442 1970-01-01 00:00:00.000001994
1     949 1970-01-01 00:00:00.000001971
2    1654 1970-01-01 00:00:00.000001970
3    1586 1970-01-01 00:00:00.000001965
4     599 1970-01-01 00:00:00.000001994

Step 2: Training Data Set Creation

Create the first aggregate feature for clustering

From each of these single ad-clicks per row, we can now generate total ad clicks per user. Let's pick a user with 
userid = 3. To find out how many ads this user has clicked overall, we have to find each row that contains userid = 3, and 
report the total number of such rows. The following commands sum the total number of ads per user and rename the columns to 
be called 'userid' and 'totalAdClicks'. Note that you may not need to aggregate (e.g. sum over many rows) if you choose a 
different feature and your data set already provides the necessary information. In the end, we want to get one row per 
user, if we are performing clustering over users.

In [11]:

adsPerUser = useradClicks.groupby('userId').sum()
adsPerUser = adsPerUser.reset_index()
adsPerUser.columns = ['userId', 'totalAdClicks'] #rename the columns

Let us display the first 5 lines of 'adsPerUser' to see if there is a column named 'totalAdClicks' containing total 
adclicks per user.

In [12]:

adsPerUser.head(n=5)

Out[12]:
#	userId 	totalAdClicks
#0 	1 	42
#1 	5 	4
#2 	9 	17
#3 	11 	4
#4 	14 	40

   userId  totalAdClicks
0       1             44
1       8             10
2       9             37
3      10             19
4      12             46


Create the second aggregate feature for clustering

Similar to what we did for adclicks, here we find out how much money in total did each user spend on buying in-app 
purchases. As an example, let's pick a user with userid = 9. To find out the total money spent by this user, we have to 
find each row that contains userid = 9, and report the sum of the column'price' of each product they purchased. The 
following commands sum the total money spent by each user and rename the columns to be called 'userid' and 'revenue'.

Note: that you can also use other aggregates, such as sum of money spent on a specific ad category by a user or on a set 
of ad categories by each user, game clicks per hour by each user etc. You are free to use any mathematical operations on 
the fields provided in the CSV files when creating features.

In [13]:

revenuePerUser = userPurchases.groupby('userId').sum()
revenuePerUser = revenuePerUser.reset_index()
revenuePerUser.columns = ['userId', 'revenue'] #rename the columns

In [14]:

revenuePerUser.head(n=5)

Out[14]:
#	userId 	revenue
#0 	1 	32
#1 	5 	2
#2 	9 	10
#3 	14 	26
#4 	17 	25

   userId  revenue
0       1     21.0
1       8     53.0
2       9     80.0
3      10     11.0
4      12    215.0


We already have the third aggregate feature (usersDOB) for clustering. 

Merge the three tables

Lets see what we have so far. We have a table called revenuePerUser, where each row contains total money a user 
(with that 'userid') has spent. We also have another table called adsPerUser where each row contains total number of ads a 
user has clicked. We will use revenuePerUser and adsPerUser as features / attributes to capture our users' behavior.

Let us combine these two attributes (features) so that each row contains both attributes per user. Let's merge these two 
tables to get one single table we can use for K-Means clustering.

In [15]:

partCombinedDF = adsPerUser.merge(revenuePerUser, on='userId') #userId, adCount, price

combinedDF = partCombinedDF.merge(usersDOB, on='userId') # userId, totalAdClicks, revenue and birthYear

Let us display the first 5 lines of the merged table. Note: Depending on what attributes you choose, you may not need to 
merge tables. You may get all your attributes from a single table.

In [16]:

combinedDF.head(n=5) #display how the merged table looks

Out[16]:
#	userId 	totalAdClicks 	revenue
#0 	1 	42 	32
#1 	5 	4 	2
#2 	9 	17 	10
#3 	14 	40 	26
#4 	17 	50 	25

   userId  totalAdClicks  revenue                     birthYear
0       1             44     21.0 1970-01-01 00:00:00.000001980
1       8             10     53.0 1970-01-01 00:00:00.000001994
2       9             37     80.0 1970-01-01 00:00:00.000001956
3      10             19     11.0 1970-01-01 00:00:00.000001997
4      12             46    215.0 1970-01-01 00:00:00.000001994


Create the final training dataset

Our training data set is almost ready. At this stage we can remove the 'userid' from each row, since 'userid' is a computer 
generated random number assigned to each user. It does not capture any behavioral aspect of a user. One way to drop the 
'userid', is to select the other two columns.

In [17]:

trainingDF = combinedDF[['totalAdClicks','revenue', 'birthYear']]
trainingDF.head(n=5)

Out[17]:
#	totalAdClicks 	revenue
#0 	42 	32
#1 	4 	2
#2 	17 	10
#3 	40 	26
#4 	50 	25

   totalAdClicks  revenue                     birthYear
0             44     21.0 1970-01-01 00:00:00.000001980
1             10     53.0 1970-01-01 00:00:00.000001994
2             37     80.0 1970-01-01 00:00:00.000001956
3             19     11.0 1970-01-01 00:00:00.000001997
4             46    215.0 1970-01-01 00:00:00.000001994


Display the dimension of the training data set. To display the dimensions of the trainingDF, simply add .shape as a 
suffix and hit enter.

In [18]:

trainingDF.shape

Out[18]:

#(832, 2)
(543, 3)

The following two commands convert the tables we created into a format that can be understood by the KMeans.train function.

line[0] refers to the first column. line[1] refers to the second column. If you have more than 2 columns in your training 
table, modify this command by adding line[2], line[3], line[4] ...

In [19]:

sqlContext = SQLContext(sc)
pDF = sqlContext.createDataFrame(trainingDF)
parsedData = pDF.rdd.map(lambda line: array([line[0], line[1], line[2]])) #totalAdClicks, revenue and birthYear

Step 3: Train to Create Cluster Centers

Train KMeans model

Here we are creating three clusters as denoted in the second argument.

In [20]:

my_kmmodel = KMeans.train(parsedData, 3, maxIterations=10, runs=10, initializationMode="random")

my_kmmodel2 = KMeans.train(parsedData, 2, maxIterations=10, runs=10, initializationMode="random")

/usr/local/Cellar/apache-spark/1.6.0/libexec/python/pyspark/mllib/clustering.py:176: UserWarning: Support for runs is 
deprecated in 1.6.0. This param will have no effect in 1.7.0.
  "Support for runs is deprecated in 1.6.0. This param will have no effect in 1.7.0.")

Display the centers of the three clusters formed

In [21]:

print(my_kmmodel.centers)

#[array([  42.05442177,  113.02040816]), array([ 29.43211679,  24.21021898])]

[array([   41.39622642,   138.96226415,  1976.9245283 ]), 
array([   25.68945869,    15.74643875,  1977.38746439]), 
array([   34.09352518,    60.97122302,  1976.20863309])]

print(my_kmmodel2.centers)

[array([   39.07608696,   115.26086957,  1976.70652174]), array([   27.39467849,    23.86474501,  1977.10864745])]

Step 4: Recommend Actions

Analyze the cluster centers

Each array denotes the center for a cluster:

#One Cluster is centered at ... array([ 29.43211679, 24.21021898])
#Other Cluster is centered at ... array([ 42.05442177, 113.02040816])



First number (field1) in each array refers to number of ad-clicks and the second number (field2) is the revenue per user. 
Compare the 1st number of each cluster to see how differently users in each cluster behave when it comes to clicking ads. 
Compare the 2nd number of each cluster to see how differently users in each cluster behave when it comes to buying stuff.

In one cluster, in general, players click on ads much more often (~1.4 times) and spend more money (~4.7 times) on 
in-app purchases. Assuming that Eglence Inc. gets paid for showing ads and for hosting in-app purchase items, we can 
use this information to increase game's revenue by increasing the prices for ads we show to the frequent-clickers, and 
charge higher fees for hosting the in-app purchase items shown to the higher revenue generating buyers.

Note: This analysis requires you to compare the cluster centers and find any significant differences in the 
corresponding feature values of the centers. The answer to this question will depend on the features you have chosen.

Some features help distinguish the clusters remarkably while others may not tell you much. At this point, if you don't 
find clear distinguishing patterns, perhaps re-running the clustering model with different numbers of clusters and 
revising the features you picked would be a good idea.

